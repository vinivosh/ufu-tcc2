{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes de Desempenho\n",
    "\n",
    "## K-Means\n",
    "\n",
    "Vamos agora realizar testes de ganho de velocidade de execução, comparando o desempenho do K-Means rodando na CPU com o do K-means rodando na GPU.\n",
    "\n",
    "Desta vez, iremos utilizar datasets bem maiores e, portanto, nada triviais — como era o caso do [*Iris* Data Set](https://archive.ics.uci.edu/ml/datasets/Iris) que foi usado anteriormente apenas como uma prova de conceito e teste de corretude.\n",
    "\n",
    "A ideia é testar se os ganhos de desempenho ao utilizarmos uma versão paralelizada em GPU diminuem, estagnam ou aumentam junto com o aumento de instâncias ou dimensionalidade do dataset.\n",
    "\n",
    "### Código Comum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kMeans as km\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import importlib\n",
    "importlib.reload(km)\n",
    "\n",
    "# Testing imports\n",
    "print(km.kMeansCPU)\n",
    "print(km.kMeansGPU)\n",
    "\n",
    "# Valor imenso para um float, para ser usado como valor inicial na variável \"slowestExecTime\"\n",
    "FLOAT_32_BIT_MAX = 3.4028237 * (10**38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1 (N > 1.000, D = 7, K = 2) — Rice (Cammeo and Osmancik)\n",
    "\n",
    "Foi utilizado aqui o Dataset **[Rice (Cammeo and Osmancik)](https://archive.ics.uci.edu/dataset/545/rice+cammeo+and+osmancik)**, que reúne dados expressando características morfológicas de grãos de arroz de duas espécies, extraídas a partir de fotos destes. Temos **7 variáveis (D = 7)** e **3.810 instâncias**.\n",
    "\n",
    "Esse dataset também contém informações de classe, definindo qual a espécie real do grão de arroz: **Cammeo** ou **Osmancik**. Portanto, haverão **2 grupos de dados (K = 2)**.\n",
    "\n",
    "Esse conjunto de dados está presente no arquivo `Rice_Cammeo_Osmancik.arff` dentro do arquivo `rice+cammeo+and+osmancik.zip` do dataset (também disponível em download direto [neste link](https://archive.ics.uci.edu/static/public/545/rice+cammeo+and+osmancik.zip)).\n",
    "\n",
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novas variáveis globais\n",
    "K = 2\n",
    "MAX_ITERATIONS = 5000\n",
    "PLOT_RESULTS = False\n",
    "DEBUG = False\n",
    "\n",
    "COMMENT_CHAR = '%'\n",
    "ALTERNATIVE_COMMENT_CHARS = ['@']\n",
    "\n",
    "datasetFilePath = './Rice_Cammeo_Osmancik.csv'\n",
    "\n",
    "# Processando o aqruivo .arff file e convertendo para um arquivo .csv válido (com linhas comentadas)\n",
    "if not os.path.exists(datasetFilePath):\n",
    "    with \\\n",
    "        open('./rice+cammeo+and+osmancik/Rice_Cammeo_Osmancik.arff', 'r') as file,\\\n",
    "        open(datasetFilePath, 'w') as fileNew:\n",
    "\n",
    "        for line in file:\n",
    "            if line[0] in ALTERNATIVE_COMMENT_CHARS:\n",
    "                fileNew.write(COMMENT_CHAR + ' ' + line[1:])\n",
    "            else:\n",
    "                fileNew.write(line)\n",
    "\n",
    "columnNames = ['Area', 'Perimeter', 'Major_Axis_Length', 'Minor_Axis_Length', 'Eccentricity', 'Convex_Area', 'Extent', 'Class']\n",
    "\n",
    "# Lendo dataset do arquivo\n",
    "with open(datasetFilePath, 'r') as datasetFile:\n",
    "    dataset = pd.read_csv(datasetFilePath, names=columnNames, sep=',', skip_blank_lines=True, comment=COMMENT_CHAR)\n",
    "\n",
    "dataset = dataset.drop(columns=['Class'])\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizando o dataset (normalização min-max), para que todos valores estejam no intervalo [1, 10]\n",
    "datasetTreated = ((dataset - dataset.min()) / (dataset.max() - dataset.min())) * 9 + 1\n",
    "\n",
    "print(f'##### Dataset (tratado e normalizado, intervalo [1, 10]) #####\\n{datasetTreated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means CPU\n",
    "# * ####################################\n",
    "\n",
    "NUMBER_OF_RUNS = 3000\n",
    "\n",
    "totalExecTime = 0.0\n",
    "slowestExecTime = -1.0\n",
    "fastestExecTime = FLOAT_32_BIT_MAX\n",
    "\n",
    "for rep in range(1, NUMBER_OF_RUNS + 1):\n",
    "    startTime = time.time()\n",
    "    km.kMeansCPU(datasetTreated, k=K, maxIter=MAX_ITERATIONS, printIter=False, plotResults=PLOT_RESULTS, debug=DEBUG)\n",
    "    # print(f'Results:\\n \\n{resultsCPU}\\n ')\n",
    "    elapsedTime = time.time() - startTime\n",
    "    print(f'Execution time for K-Means CPU run #{rep}: {elapsedTime}')\n",
    "    if elapsedTime < fastestExecTime: fastestExecTime = elapsedTime\n",
    "    if elapsedTime > slowestExecTime: slowestExecTime = elapsedTime\n",
    "    totalExecTime += elapsedTime\n",
    "    # print(f'Average execution time for K-Means CPU until now: {totalExecTime / rep}')\n",
    "\n",
    "print(f' \\nAverage execution time for K-Means CPU: {totalExecTime / NUMBER_OF_RUNS}')\n",
    "print(f'Slowest execution time for K-Means CPU: {slowestExecTime}')\n",
    "print(f'Fastest execution time for K-Means CPU: {fastestExecTime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means GPU\n",
    "# * ####################################\n",
    "\n",
    "NUMBER_OF_RUNS = 3000\n",
    "\n",
    "totalExecTime = 0.0\n",
    "slowestExecTime = -1.0\n",
    "fastestExecTime = FLOAT_32_BIT_MAX\n",
    "\n",
    "for rep in range(1, NUMBER_OF_RUNS + 1):\n",
    "    startTime = time.time()\n",
    "    km.kMeansGPU(datasetTreated, k=K, maxIter=MAX_ITERATIONS, printIter=False, plotResults=PLOT_RESULTS, debug=DEBUG)\n",
    "    # print(f'Results:\\n \\n{resultsGPU}\\n ')\n",
    "    elapsedTime = time.time() - startTime\n",
    "    print(f'Execution time for K-Means GPU run #{rep}: {elapsedTime}')\n",
    "    if elapsedTime < fastestExecTime: fastestExecTime = elapsedTime\n",
    "    if elapsedTime > slowestExecTime: slowestExecTime = elapsedTime\n",
    "    totalExecTime += elapsedTime\n",
    "    # print(f'Average execution time for K-Means GPU until now: {totalExecTime / rep}')\n",
    "\n",
    "print(f' \\nAverage execution time for K-Means GPU: {totalExecTime / NUMBER_OF_RUNS}')\n",
    "print(f'Slowest execution time for K-Means GPU: {slowestExecTime}')\n",
    "print(f'Fastest execution time for K-Means GPU: {fastestExecTime}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2 (N > 10.000, D = 8, K = 2) — HTRU2\n",
    "\n",
    "Foi utilizado aqui o Dataset **[HTRU2 (High Time Resolution Universe 2)](https://archive.ics.uci.edu/dataset/372/htru2)**, que reúne dados a respeito de emissões de sinais de rádio de banda larga obtidos através de leituras feitas com telescópios de rádio. É um dos resultados da busca por pulsares, estrelas de neutrôn que possuem uma rotação rápida e que emitem sinais de rádio banda larga detectáveis do nosso planeta. Temos **8 variáveis (D = 8)** e **17.898 instâncias**.\n",
    "\n",
    "Esse dataset também contém informações de classe, definindo se a leitura é **positiva** ou **negativa**, a respeito do sinal candidato de fato originar ou não de um pulsar. Portanto, haverão **2 grupos de dados (K = 2)**.\n",
    "\n",
    "Esse conjunto de dados está presente no arquivo `HTRU_2.csv` dentro do arquivo `HTRU_2.zip` do dataset (também disponível em download direto [neste link](https://archive.ics.uci.edu/static/public/372/htru2.zip)).\n",
    "\n",
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novas variáveis globais\n",
    "K = 2\n",
    "MAX_ITERATIONS = 5000\n",
    "PLOT_RESULTS = False\n",
    "DEBUG = False\n",
    "\n",
    "datasetFilePath = './htru2/HTRU_2.csv'\n",
    "\n",
    "columnNames = ['mean_IP', 'std_dev_IP', 'exc_kurt_IP', 'skew_IP', 'mean_DM_SNR', 'std_dev_DM_SNR', 'exc_kurt_DM_SNR', 'skew_DM_SNR', 'is_positive']\n",
    "\n",
    "# Lendo dataset do arquivo\n",
    "with open(datasetFilePath, 'r') as datasetFile:\n",
    "    dataset = pd.read_csv(datasetFilePath, names=columnNames, sep=',')\n",
    "\n",
    "dataset = dataset.drop(columns=['is_positive'])\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizando o dataset (normalização min-max), para que todos valores estejam no intervalo [1, 10]\n",
    "datasetTreated = ((dataset - dataset.min()) / (dataset.max() - dataset.min())) * 9 + 1\n",
    "\n",
    "print(f'##### Dataset (tratado e normalizado, intervalo [1, 10]) #####\\n{datasetTreated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means CPU\n",
    "# * ####################################\n",
    "\n",
    "NUMBER_OF_RUNS = 500\n",
    "\n",
    "totalExecTime = 0.0\n",
    "slowestExecTime = -1.0\n",
    "fastestExecTime = FLOAT_32_BIT_MAX\n",
    "\n",
    "for rep in range(1, NUMBER_OF_RUNS + 1):\n",
    "    startTime = time.time()\n",
    "    km.kMeansCPU(datasetTreated, k=K, maxIter=MAX_ITERATIONS, printIter=False, plotResults=PLOT_RESULTS, debug=DEBUG)\n",
    "    # print(f'Results:\\n \\n{resultsCPU}\\n ')\n",
    "    elapsedTime = time.time() - startTime\n",
    "    print(f'Execution time for K-Means CPU run #{rep}: {elapsedTime}')\n",
    "    if elapsedTime < fastestExecTime: fastestExecTime = elapsedTime\n",
    "    if elapsedTime > slowestExecTime: slowestExecTime = elapsedTime\n",
    "    totalExecTime += elapsedTime\n",
    "    # print(f'Average execution time for K-Means CPU until now: {totalExecTime / rep}')\n",
    "\n",
    "print(f' \\nAverage execution time for K-Means CPU: {totalExecTime / NUMBER_OF_RUNS}')\n",
    "print(f'Slowest execution time for K-Means CPU: {slowestExecTime}')\n",
    "print(f'Fastest execution time for K-Means CPU: {fastestExecTime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means GPU\n",
    "# * ####################################\n",
    "\n",
    "NUMBER_OF_RUNS = 500\n",
    "\n",
    "totalExecTime = 0.0\n",
    "slowestExecTime = -1.0\n",
    "fastestExecTime = FLOAT_32_BIT_MAX\n",
    "\n",
    "for rep in range(1, NUMBER_OF_RUNS + 1):\n",
    "    startTime = time.time()\n",
    "    km.kMeansGPU(datasetTreated, k=K, maxIter=MAX_ITERATIONS, printIter=False, plotResults=PLOT_RESULTS, debug=DEBUG)\n",
    "    # print(f'Results:\\n \\n{resultsGPU}\\n ')\n",
    "    elapsedTime = time.time() - startTime\n",
    "    print(f'Execution time for K-Means GPU run #{rep}: {elapsedTime}')\n",
    "    if elapsedTime < fastestExecTime: fastestExecTime = elapsedTime\n",
    "    if elapsedTime > slowestExecTime: slowestExecTime = elapsedTime\n",
    "    totalExecTime += elapsedTime\n",
    "    # print(f'Average execution time for K-Means GPU until now: {totalExecTime / rep}')\n",
    "\n",
    "print(f' \\nAverage execution time for K-Means GPU: {totalExecTime / NUMBER_OF_RUNS}')\n",
    "print(f'Slowest execution time for K-Means GPU: {slowestExecTime}')\n",
    "print(f'Fastest execution time for K-Means GPU: {fastestExecTime}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3 (N > 100.000, D = 50, K = 2) — MiniBooNE\n",
    "\n",
    "Foi utilizado aqui o Dataset **[MiniBooNE Particle Identification](https://archive.ics.uci.edu/dataset/199/miniboone+particle+identification)**, que reúne dados a respeito de partículas detectadas no experimento *MiniBooNE* (*Mini Booster Neutrino Experiment*), conduzido no laboratório americano *Fermilab*. Cada detecção de partícula é descrita por **50 variáveis reais (D = 50)** e há **129.596 instâncias no total**.\n",
    "\n",
    "As primeiras 36.488 instâncias são detecções de neutrinos do elétron (sinal) e as 93.108 restantes são de neutrinos do múon (ruído de fundo). Assim, as informações de classe desse dataset estão implícitas, expressa pela ordem das instâncias no arquivo. Como temos duas classes, haverão **2 grupos de dados (K = 2)**.\n",
    "\n",
    "Esse conjunto de dados está presente no arquivo `MiniBooNE_PID.txt` dentro do arquivo `miniboone+particle+identification.zip` do dataset (também disponível em download direto [neste link](https://archive.ics.uci.edu/static/public/199/miniboone+particle+identification.zip)).\n",
    "\n",
    "Foi necessário, neste dataset, realizar um **pré-processamento** para **remoção de outliers**. Originalmente, há 130.064 instâncias no total (36.499 sinal e 93.565 ruído). Porém, existem 468 instâncias (11 sinal e 457 ruído) que são extremos outliers, possuindo o valor -999.0 em todas as 50 variáveis — provavelmente advindos de algum erro de detecção. A presença destes outliers causava a criação de um cluster contendo apenas estes outliers, diminuindo muito o tempo de execução do algoritmo de maneira artificial. Estes outliers tiveram que ser removidos. Note que poderíamos ter solucionado este problema com outra abordagem: aumentar K para 3, criando um cluster novo para conter apenas os outliers. Isso, no entanto, seria mais custoso computacionalmente do que a remoção das instâncias.\n",
    "\n",
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novas variáveis globais\n",
    "K = 2\n",
    "MAX_ITERATIONS = 5000\n",
    "PLOT_RESULTS = False\n",
    "DEBUG = False\n",
    "\n",
    "COMMENT_CHAR = '#'\n",
    "\n",
    "# As primeiras 36.499 instâncias são consideradas um sinal, e o resto como ruído\n",
    "N_OF_SIGNAL_LINES = 36499\n",
    "\n",
    "datasetFilePath = './MiniBooNE_PID.csv'\n",
    "\n",
    "# Processando o aqruivo .txt file e convertendo para um arquivo .csv válido (com a primeira linha comentada, removendo o leading whitespace, e trocando o separador de \"  \" ou \" \" para \",\")\n",
    "if not os.path.exists(datasetFilePath):\n",
    "    with \\\n",
    "        open('./MiniBooNE_PID.txt', 'r') as file,\\\n",
    "        open(datasetFilePath, 'w') as fileNew:\n",
    "\n",
    "        print('Processing MiniBooNE_PID.txt...\\n ')\n",
    "\n",
    "        # Removendo outliers com -999.0 de valor nas 50 variáveis. Há 468 destas instâncias\n",
    "        outlierString = '''-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03'''\n",
    "\n",
    "        index = 1\n",
    "        signalInstRemoved = 0\n",
    "        noiseInstRemoved = 0\n",
    "        for line in file:\n",
    "            if index != 1:\n",
    "                lineToWrite = line.strip(' ').replace('  ', ' ').replace(' ', ',')\n",
    "                if outlierString not in lineToWrite:\n",
    "                    fileNew.write(lineToWrite)\n",
    "                else:\n",
    "                    if index - 1 <= N_OF_SIGNAL_LINES:\n",
    "                        # print(f'Instance (signal) #{index - 1} removed...')\n",
    "                        signalInstRemoved += 1\n",
    "                    else:\n",
    "                        # print(f'Instance (noise) #{index - 1} removed...')\n",
    "                        noiseInstRemoved += 1\n",
    "            # else:\n",
    "            #     fileNew.write(COMMENT_CHAR + ' ' + line.strip(' ').replace('  ', ' '))\n",
    "            index += 1\n",
    "\n",
    "        print(f'Signal outlier instances removed = {signalInstRemoved}')\n",
    "        print(f'Noise outlier instances removed = {noiseInstRemoved}\\n ')\n",
    "\n",
    "        print(f'Processed dataset saved in {datasetFilePath} with success!\\n ')\n",
    "else:\n",
    "    print(f'Processed dataset found in {datasetFilePath}. No need for processing!\\n ')\n",
    "\n",
    "columnNames = [f'id_var_{i}' for i in range(1, 50 + 1) ]\n",
    "\n",
    "# Lendo dataset do arquivo\n",
    "with open(datasetFilePath, 'r') as datasetFile:\n",
    "    dataset = pd.read_csv(datasetFile, names=columnNames, sep=',', skip_blank_lines=True)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizando o dataset (normalização min-max), para que todos valores estejam no intervalo [1, 10]\n",
    "datasetTreated = ((dataset - dataset.min()) / (dataset.max() - dataset.min())) * 9 + 1\n",
    "\n",
    "print(f'##### Dataset (tratado e normalizado, intervalo [1, 10]) #####\\n{datasetTreated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means CPU\n",
    "# * ####################################\n",
    "\n",
    "NUMBER_OF_RUNS = 200\n",
    "\n",
    "totalExecTime = 0.0\n",
    "slowestExecTime = -1.0\n",
    "fastestExecTime = FLOAT_32_BIT_MAX\n",
    "\n",
    "for rep in range(1, NUMBER_OF_RUNS + 1):\n",
    "    startTime = time.time()\n",
    "    km.kMeansCPU(datasetTreated, k=K, maxIter=MAX_ITERATIONS, printIter=False, plotResults=PLOT_RESULTS, debug=DEBUG)\n",
    "    # print(f'Results:\\n \\n{resultsCPU}\\n ')\n",
    "    elapsedTime = time.time() - startTime\n",
    "    print(f'Execution time for K-Means CPU run #{rep}: {elapsedTime}')\n",
    "    if elapsedTime < fastestExecTime: fastestExecTime = elapsedTime\n",
    "    if elapsedTime > slowestExecTime: slowestExecTime = elapsedTime\n",
    "    totalExecTime += elapsedTime\n",
    "    # print(f'Average execution time for K-Means CPU until now: {totalExecTime / rep}')\n",
    "\n",
    "print(f' \\nAverage execution time for K-Means CPU: {totalExecTime / NUMBER_OF_RUNS}')\n",
    "print(f'Slowest execution time for K-Means CPU: {slowestExecTime}')\n",
    "print(f'Fastest execution time for K-Means CPU: {fastestExecTime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means GPU\n",
    "# * ####################################\n",
    "\n",
    "NUMBER_OF_RUNS = 200\n",
    "\n",
    "totalExecTime = 0.0\n",
    "slowestExecTime = -1.0\n",
    "fastestExecTime = FLOAT_32_BIT_MAX\n",
    "\n",
    "for rep in range(1, NUMBER_OF_RUNS + 1):\n",
    "    startTime = time.time()\n",
    "    km.kMeansGPU(datasetTreated, k=K, maxIter=MAX_ITERATIONS, printIter=False, plotResults=PLOT_RESULTS, debug=DEBUG)\n",
    "    # print(f'Results:\\n \\n{resultsGPU}\\n ')\n",
    "    elapsedTime = time.time() - startTime\n",
    "    print(f'Execution time for K-Means GPU run #{rep}: {elapsedTime}')\n",
    "    if elapsedTime < fastestExecTime: fastestExecTime = elapsedTime\n",
    "    if elapsedTime > slowestExecTime: slowestExecTime = elapsedTime\n",
    "    totalExecTime += elapsedTime\n",
    "    # print(f'Average execution time for K-Means GPU until now: {totalExecTime / rep}')\n",
    "\n",
    "print(f' \\nAverage execution time for K-Means GPU: {totalExecTime / NUMBER_OF_RUNS}')\n",
    "print(f'Slowest execution time for K-Means GPU: {slowestExecTime}')\n",
    "print(f'Fastest execution time for K-Means GPU: {fastestExecTime}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 4 (N > 1.000.000, D = 8) — WESAD\n",
    "\n",
    "Foi utilizado aqui um sub-conjunto dos dados do Dataset **[WESAD (Wearable Stress and Affect Detection)](https://archive.ics.uci.edu/dataset/465/wesad+wearable+stress+and+affect+detection)**, que reúne dados, fisiológicos e de movimento, de diversos sensores presentes em aparelhos *wearables* usados por 15 pacientes diferentes em testes laboratoriais. Um aparelho foi usado no peitoral e outro no pulso dos pacientes.\n",
    "\n",
    "Esse dataset também contém informações de classe, definindo momentos dos testes como pertencendo à três classificações de emoção do paciente: **referência**, **estresse** ou **diversão**. Portanto, haverão **3 grupos de dados (K = 3)**.\n",
    "\n",
    "O sub-conjunto de dados utilizado foi: dados obtidos apenas através do **aparelho usado no peito** do paciente, e apenas do **paciente #4**. Utilizando este sub-conjunto, temos **8 variáveis (D = 8)** e **4.588.552 instâncias**, cada uma sendo uma leitura ao longo do tempo do teste laboratorial (leituras realizadas na frequência de 700hz).\n",
    "\n",
    "Esse sub-conjunto de dados está presente no arquivo `S4/S4_respiban.txt` dentro do arquivo `WESAD.zip` do dataset (também disponível em download direto [neste link](https://uni-siegen.sciebo.de/s/HGdUkoNlW1Ub0Gx/download)).\n",
    "\n",
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novas variáveis globais\n",
    "K = 3\n",
    "MAX_ITERATIONS = 5000\n",
    "PLOT_RESULTS = False\n",
    "DEBUG = False\n",
    "\n",
    "datasetFilePath = './WESAD/S4/S4_respiban.txt'\n",
    "columnNames = ['index', 'DI', 'ECG', 'EDA', 'EMG', 'TEMP', 'spatialX', 'spatialY', 'spatialZ', 'RESPIRATION', '_ignore_']\n",
    "\n",
    "# Lendo dataset do arquivo\n",
    "with open(datasetFilePath, 'r') as datasetFile:\n",
    "    dataset = pd.read_csv(datasetFilePath, names=columnNames, sep='\\t', index_col=0, skip_blank_lines=True, comment='#')\n",
    "\n",
    "dataset = dataset.drop(columns=['DI', '_ignore_'])\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizando o dataset (normalização min-max), para que todos valores estejam no intervalo [1, 10]\n",
    "datasetTreated = ((dataset - dataset.min()) / (dataset.max() - dataset.min())) * 9 + 1\n",
    "\n",
    "print(f'##### Dataset (tratado e normalizado, intervalo [1, 10]) #####\\n{datasetTreated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means CPU\n",
    "# * ####################################\n",
    "\n",
    "NUMBER_OF_RUNS = 100\n",
    "\n",
    "totalExecTime = 0.0\n",
    "slowestExecTime = -1.0\n",
    "fastestExecTime = FLOAT_32_BIT_MAX\n",
    "\n",
    "for rep in range(1, NUMBER_OF_RUNS + 1):\n",
    "    startTime = time.time()\n",
    "    km.kMeansCPU(datasetTreated, k=K, maxIter=MAX_ITERATIONS, printIter=False, plotResults=PLOT_RESULTS, debug=DEBUG)\n",
    "    # print(f'Results:\\n \\n{resultsCPU}\\n ')\n",
    "    elapsedTime = time.time() - startTime\n",
    "    print(f'Execution time for K-Means CPU run #{rep}: {elapsedTime}')\n",
    "    if elapsedTime < fastestExecTime: fastestExecTime = elapsedTime\n",
    "    if elapsedTime > slowestExecTime: slowestExecTime = elapsedTime\n",
    "    totalExecTime += elapsedTime\n",
    "    # print(f'Average execution time for K-Means CPU until now: {totalExecTime / rep}')\n",
    "\n",
    "print(f' \\nAverage execution time for K-Means CPU: {totalExecTime / NUMBER_OF_RUNS}')\n",
    "print(f'Slowest execution time for K-Means CPU: {slowestExecTime}')\n",
    "print(f'Fastest execution time for K-Means CPU: {fastestExecTime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means GPU\n",
    "# * ####################################\n",
    "\n",
    "NUMBER_OF_RUNS = 100\n",
    "\n",
    "totalExecTime = 0.0\n",
    "slowestExecTime = -1.0\n",
    "fastestExecTime = FLOAT_32_BIT_MAX\n",
    "\n",
    "for rep in range(1, NUMBER_OF_RUNS + 1):\n",
    "    startTime = time.time()\n",
    "    km.kMeansGPU(datasetTreated, k=K, maxIter=MAX_ITERATIONS, printIter=False, plotResults=PLOT_RESULTS, debug=DEBUG)\n",
    "    # print(f'Results:\\n \\n{resultsGPU}\\n ')\n",
    "    elapsedTime = time.time() - startTime\n",
    "    print(f'Execution time for K-Means GPU run #{rep}: {elapsedTime}')\n",
    "    if elapsedTime < fastestExecTime: fastestExecTime = elapsedTime\n",
    "    if elapsedTime > slowestExecTime: slowestExecTime = elapsedTime\n",
    "    totalExecTime += elapsedTime\n",
    "    # print(f'Average execution time for K-Means GPU until now: {totalExecTime / rep}')\n",
    "\n",
    "print(f' \\nAverage execution time for K-Means GPU: {totalExecTime / NUMBER_OF_RUNS}')\n",
    "print(f'Slowest execution time for K-Means GPU: {slowestExecTime}')\n",
    "print(f'Fastest execution time for K-Means GPU: {fastestExecTime}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados\n",
    "\n",
    "> Resultados completos disponíveis no arquivo `code/examples-and-tests/speedupTestsRawResults.txt`\n",
    "\n",
    "| |Tempo médio (50 execuções)|Speedup Médio|\n",
    "|-|-|-|\n",
    "|K-Means CPU|~129,81s|-|\n",
    "|K-Means GPU|~27,87s|~4,65x|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 5 (N > 10.000.000, D = 3, K = 6) — HHAR\n",
    "\n",
    "Foi utilizado aqui um sub-conjunto dos dados do Dataset **[Heterogeneity Human Activity Recognition (HHAR)](https://archive.ics.uci.edu/dataset/344/heterogeneity+activity+recognition)**, que reúne dados de movimento do giroscópio e acelerômetro presentes em aparelhos celulares (*smartphones*) e relógios (*smartwatches*) usados por 9 usuários diferentes ao realizar diversas atividades físicas diferentes ou estando em repouso.\n",
    "\n",
    "Esse dataset também contém informações de classe, definindo momentos dos testes como pertencendo a uma de seis atividades realizadas: **ciclismo**, **repouso (sentado)**, **repouso (em pé)**, **andar**, **subir escadas** e **descer escadas**. Portanto, haverão **6 grupos de dados (K = 6)**.\n",
    "\n",
    "O sub-conjunto de dados utilizado foi: dados obtidos apenas através do **giroscópio do smartphone** do usuário. Utilizando este sub-conjunto, temos **3 variáveis (D = 3)** e **4.588.552 instâncias**, cada uma sendo uma leitura ao longo do tempo do experimento.\n",
    "\n",
    "Esse sub-conjunto de dados está presente no arquivo `Activity recognition exp/Phones_gyroscope.csv` dentro do arquivo `heterogeneity+activity+recognition.zip` do dataset (também disponível em download direto [neste link](https://archive.ics.uci.edu/static/public/344/heterogeneity+activity+recognition.zip)).\n",
    "\n",
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novas variáveis globais\n",
    "K = 6\n",
    "MAX_ITERATIONS = 4294967296\n",
    "PLOT_RESULTS = False\n",
    "DEBUG = False\n",
    "\n",
    "datasetFilePath = './heterogeneity+activity+recognition/Activity recognition exp/Phones_gyroscope.csv'\n",
    "columnNames = ['index', 'arrival_time', 'creation_Time', 'x', 'y', 'z', 'user', 'model', 'device', 'gt']\n",
    "\n",
    "# Lendo dataset do arquivo\n",
    "with open(datasetFilePath, 'r') as datasetFile:\n",
    "    dataset = pd.read_csv(datasetFile, names=columnNames, header=0, sep=',', index_col=0)\n",
    "\n",
    "dataset = dataset.drop(columns=['arrival_time', 'creation_Time', 'user', 'model', 'device', 'gt'])\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizando o dataset (normalização min-max), para que todos valores estejam no intervalo [1, 10]\n",
    "datasetTreated = ((dataset - dataset.min()) / (dataset.max() - dataset.min())) * 9 + 1\n",
    "\n",
    "print(f'##### Dataset (tratado e normalizado, intervalo [1, 10]) #####\\n{datasetTreated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means CPU\n",
    "# * ####################################\n",
    "\n",
    "NUMBER_OF_RUNS = 5\n",
    "\n",
    "totalExecTime = 0.0\n",
    "slowestExecTime = -1.0\n",
    "fastestExecTime = FLOAT_32_BIT_MAX\n",
    "\n",
    "for rep in range(1, NUMBER_OF_RUNS + 1):\n",
    "    startTime = time.time()\n",
    "    km.kMeansCPU(datasetTreated, k=K, maxIter=MAX_ITERATIONS, printIter=False, plotResults=PLOT_RESULTS, debug=DEBUG)\n",
    "    # print(f'Results:\\n \\n{resultsCPU}\\n ')\n",
    "    elapsedTime = time.time() - startTime\n",
    "    print(f'Execution time for K-Means CPU run #{rep}: {elapsedTime}')\n",
    "    if elapsedTime < fastestExecTime: fastestExecTime = elapsedTime\n",
    "    if elapsedTime > slowestExecTime: slowestExecTime = elapsedTime\n",
    "    totalExecTime += elapsedTime\n",
    "    # print(f'Average execution time for K-Means CPU until now: {totalExecTime / rep}')\n",
    "\n",
    "print(f' \\nAverage execution time for K-Means CPU: {totalExecTime / NUMBER_OF_RUNS}')\n",
    "print(f'Slowest execution time for K-Means CPU: {slowestExecTime}')\n",
    "print(f'Fastest execution time for K-Means CPU: {fastestExecTime}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means GPU\n",
    "# * ####################################\n",
    "\n",
    "NUMBER_OF_RUNS = 5\n",
    "\n",
    "totalExecTime = 0.0\n",
    "slowestExecTime = -1.0\n",
    "fastestExecTime = FLOAT_32_BIT_MAX\n",
    "\n",
    "for rep in range(1, NUMBER_OF_RUNS + 1):\n",
    "    startTime = time.time()\n",
    "    km.kMeansGPU(datasetTreated, k=K, maxIter=MAX_ITERATIONS, printIter=False, plotResults=PLOT_RESULTS, debug=DEBUG)\n",
    "    # print(f'Results:\\n \\n{resultsGPU}\\n ')\n",
    "    elapsedTime = time.time() - startTime\n",
    "    print(f'Execution time for K-Means GPU run #{rep}: {elapsedTime}')\n",
    "    if elapsedTime < fastestExecTime: fastestExecTime = elapsedTime\n",
    "    if elapsedTime > slowestExecTime: slowestExecTime = elapsedTime\n",
    "    totalExecTime += elapsedTime\n",
    "    # print(f'Average execution time for K-Means GPU until now: {totalExecTime / rep}')\n",
    "\n",
    "print(f' \\nAverage execution time for K-Means GPU: {totalExecTime / NUMBER_OF_RUNS}')\n",
    "print(f'Slowest execution time for K-Means GPU: {slowestExecTime}')\n",
    "print(f'Fastest execution time for K-Means GPU: {fastestExecTime}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
