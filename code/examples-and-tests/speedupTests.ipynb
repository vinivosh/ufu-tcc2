{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes de Desempenho\n",
    "\n",
    "## K-Means\n",
    "\n",
    "Vamos agora realizar testes de ganho de velocidade de execução, comparando o desempenho do K-Means rodando na CPU com o do K-means rodando na GPU.\n",
    "\n",
    "Desta vez, iremos utilizar datasets bem maiores e, portanto, nada triviais — como era o caso do [*Iris* Data Set](https://archive.ics.uci.edu/ml/datasets/Iris) que foi usado anteriormente apenas como uma prova de conceito e teste de corretude.\n",
    "\n",
    "A ideia é testar se os ganhos de desempenho ao utilizarmos uma versão paralelizada em GPU diminuem, estagnam ou aumentam junto com o aumento de instâncias ou dimensionalidade do dataset.\n",
    "\n",
    "Também será testado se houve diferença de precisção de cada classificação. Isso é realizado usando a função `getClassificationHits()`, explicada mais a fundo nos cadernos Jupyter `kMeansCPU.ipynb` e `kMeansGPU.ipynb`.\n",
    "\n",
    "### Código Comum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function kMeansCPU at 0x7d3593bc9440>\n",
      "<function kMeansGPU at 0x7d3593ae6d40>\n",
      "<function getClassificationHits at 0x7d3593ae7e20>\n",
      "env: NUMBA_CUDA_LOW_OCCUPANCY_WARNINGS=0\n"
     ]
    }
   ],
   "source": [
    "import kMeans as km\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import importlib\n",
    "importlib.reload(km)\n",
    "\n",
    "# Testing imports\n",
    "print(km.kMeansCPU)\n",
    "print(km.kMeansGPU)\n",
    "print(km.getClassificationHits)\n",
    "\n",
    "# Se verdadeiro, os testes incluirão a contagem de acertos dos resultados dos algoritmos. Isso pode demorar MUITO (>4h por execução no dataset 5)!\n",
    "TEST_CORRECTEDNESS = False\n",
    "\n",
    "# Valor efetivamente infinito para um float, para ser usado como valor inicial na variável \"fastestExecTime\"\n",
    "FLOAT_MAX = float('inf')\n",
    "\n",
    "# Configurando Numba para não reportar erros de baixa ocupação dos streaming multiprocessors (SMs) da GPU\n",
    "# Não suprimir estes erros gera um overhead bem considerável, ocasionalmente, em algumas execuções do K-Means GPU\n",
    "%set_env NUMBA_CUDA_LOW_OCCUPANCY_WARNINGS 0\n",
    "\n",
    "# Função para rodar os testes\n",
    "def runTests(mode:str='GPU', runs:int=10, countHits:bool=True):\n",
    "    '''Essa função depende de diversas variáveis declaradas anteriormente. Portanto, é inútil fora deste caderno Jupyter!'''\n",
    "\n",
    "    mode = mode.upper()\n",
    "    if mode == 'CPU': kMeans = km.kMeansCPU\n",
    "    elif mode == 'GPU': kMeans = km.kMeansGPU\n",
    "    else: raise ValueError('Unknown mode!')\n",
    "\n",
    "    totalExecTime = 0.0\n",
    "    slowestExecTime = -1.0\n",
    "    fastestExecTime = FLOAT_MAX\n",
    "\n",
    "    totalHits = 0\n",
    "    totalHitsTime = 0.0\n",
    "\n",
    "    for rep in range(1, runs + 1):\n",
    "        startTime = time.perf_counter()\n",
    "        results = kMeans(datasetTreated, k=K, maxIter=MAX_ITERATIONS, printIter=False, plotResults=PLOT_RESULTS, debug=DEBUG)\n",
    "        elapsedTime = time.perf_counter() - startTime\n",
    "        if elapsedTime < fastestExecTime: fastestExecTime = elapsedTime\n",
    "        if elapsedTime > slowestExecTime: slowestExecTime = elapsedTime\n",
    "        totalExecTime += elapsedTime\n",
    "        print(f'Execution K-Means {mode} run #{rep}: {elapsedTime}; curr avg: {totalExecTime / rep}; ', end='')\n",
    "\n",
    "        if countHits:\n",
    "            # Verificando acertos\n",
    "            # Converting from numpy arrays to panda's dataframes, if needed\n",
    "            if results.__class__.__name__ != pd.DataFrame.__class__.__name__: results = pd.DataFrame(results)\n",
    "            startTime = time.perf_counter()\n",
    "            hits, _, _  = km.getClassificationHits(results, dataset, classColumnName, classes, debug=DEBUG)\n",
    "            elapsedTime = time.perf_counter() - startTime\n",
    "            totalHits += hits\n",
    "            totalHitsTime += elapsedTime\n",
    "            print(f'Hits: {hits} (done in {elapsedTime:.4f}); curr avg hits: {totalHits / rep}', end='')\n",
    "\n",
    "        print('\\n', end='')\n",
    "\n",
    "    print(f' \\nAvg exec K-Means {mode}: {totalExecTime / runs}')\n",
    "    print(f'Max exec K-Means {mode}: {slowestExecTime}')\n",
    "    print(f'Min exec time K-Means {mode}: {fastestExecTime}')\n",
    "\n",
    "    if countHits:\n",
    "        print(f' \\nAverage hits: {totalHits / runs}')\n",
    "        print(f'Avg exec K-Means {mode} classificationHits(): {totalHitsTime / runs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1 (N > 1.000, D = 7, K = 2) — Rice (Cammeo and Osmancik)\n",
    "\n",
    "Foi utilizado aqui o Dataset **[Rice (Cammeo and Osmancik)](https://archive.ics.uci.edu/dataset/545/rice+cammeo+and+osmancik)**, que reúne dados expressando características morfológicas de grãos de arroz de duas espécies, extraídas a partir de fotos destes. Temos **7 variáveis (D = 7)** e **3.810 instâncias**.\n",
    "\n",
    "Esse dataset também contém informações de classe, definindo qual a espécie real do grão de arroz: **Cammeo** ou **Osmancik**. Portanto, haverão **2 grupos de dados (K = 2)**.\n",
    "\n",
    "Esse conjunto de dados está presente no arquivo `Rice_Cammeo_Osmancik.arff` dentro do arquivo `rice+cammeo+and+osmancik.zip` do dataset (também disponível em download direto [neste link](https://archive.ics.uci.edu/static/public/545/rice+cammeo+and+osmancik.zip)).\n",
    "\n",
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Area   Perimeter  Major_Axis_Length  Minor_Axis_Length  Eccentricity   \n",
      "0     15231  525.578979         229.749878          85.093788      0.928882  \\\n",
      "1     14656  494.311005         206.020065          91.730972      0.895405   \n",
      "2     14634  501.122009         214.106781          87.768288      0.912118   \n",
      "3     13176  458.342987         193.337387          87.448395      0.891861   \n",
      "4     14688  507.166992         211.743378          89.312454      0.906691   \n",
      "...     ...         ...                ...                ...           ...   \n",
      "3805  11441  415.858002         170.486771          85.756592      0.864280   \n",
      "3806  11625  421.390015         167.714798          89.462570      0.845850   \n",
      "3807  12437  442.498993         183.572922          86.801979      0.881144   \n",
      "3808   9882  392.296997         161.193985          78.210480      0.874406   \n",
      "3809  11434  404.709991         161.079269          90.868195      0.825692   \n",
      "\n",
      "      Convex_Area    Extent  \n",
      "0           15617  0.572896  \n",
      "1           15072  0.615436  \n",
      "2           14954  0.693259  \n",
      "3           13368  0.640669  \n",
      "4           15262  0.646024  \n",
      "...           ...       ...  \n",
      "3805        11628  0.681012  \n",
      "3806        11904  0.694279  \n",
      "3807        12645  0.626739  \n",
      "3808        10097  0.659064  \n",
      "3809        11591  0.802949  \n",
      "\n",
      "[3810 rows x 7 columns]\n",
      "Classes (from column \"Class\"): ['Cammeo' 'Osmancik']\n"
     ]
    }
   ],
   "source": [
    "# Novas variáveis globais\n",
    "K = 2\n",
    "MAX_ITERATIONS = 60\n",
    "PLOT_RESULTS = False\n",
    "DEBUG = False\n",
    "\n",
    "COMMENT_CHAR = '%'\n",
    "ALTERNATIVE_COMMENT_CHARS = ['@']\n",
    "\n",
    "datasetFilePath = './Rice_Cammeo_Osmancik.csv'\n",
    "\n",
    "# Processando o aqruivo .arff file e convertendo para um arquivo .csv válido (com linhas comentadas)\n",
    "if not os.path.exists(datasetFilePath):\n",
    "    with \\\n",
    "        open('./rice+cammeo+and+osmancik/Rice_Cammeo_Osmancik.arff', 'r') as file,\\\n",
    "        open(datasetFilePath, 'w') as fileNew:\n",
    "\n",
    "        for line in file:\n",
    "            if line[0] in ALTERNATIVE_COMMENT_CHARS:\n",
    "                fileNew.write(COMMENT_CHAR + ' ' + line[1:])\n",
    "            else:\n",
    "                fileNew.write(line)\n",
    "\n",
    "columnNames = ['Area', 'Perimeter', 'Major_Axis_Length', 'Minor_Axis_Length', 'Eccentricity', 'Convex_Area', 'Extent', 'Class']\n",
    "\n",
    "# Lendo dataset do arquivo\n",
    "with open(datasetFilePath, 'r') as datasetFile:\n",
    "    dataset = pd.read_csv(datasetFilePath, names=columnNames, sep=',', skip_blank_lines=True, comment=COMMENT_CHAR)\n",
    "\n",
    "datasetTreated = dataset.drop(columns=['Class'])\n",
    "print(datasetTreated)\n",
    "\n",
    "classColumnName = 'Class'\n",
    "classes = dataset[classColumnName].unique()\n",
    "\n",
    "print(f'Classes (from column \"{classColumnName}\"): {classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Dataset (tratado e normalizado, intervalo [1, 10]) #####\n",
      "          Area  Perimeter  Major_Axis_Length  Minor_Axis_Length  Eccentricity   \n",
      "0     7.083436   8.913085           9.110943           5.791756      8.992095  \\\n",
      "1     6.627970   7.426854           6.832784           7.035968      7.227819   \n",
      "2     6.610544   7.750595           7.609142           6.293120      8.108617   \n",
      "3     5.455642   5.717221           5.615196           6.233153      7.041041   \n",
      "4     6.653318   8.037925           7.382246           6.582591      7.822599   \n",
      "...        ...        ...                ...                ...           ...   \n",
      "3805  4.081324   3.697823           3.421444           5.916006      5.587521   \n",
      "3806  4.227073   3.960771           3.155323           6.610732      4.616211   \n",
      "3807  4.870269   4.964124           4.677767           6.111975      6.476267   \n",
      "3808  2.846418   2.577921           2.529299           4.501406      6.121153   \n",
      "3809  4.075779   3.167936           2.518285           6.874231      3.553875   \n",
      "\n",
      "      Convex_Area    Extent  \n",
      "0        7.245253  2.868194  \n",
      "1        6.814082  3.921078  \n",
      "2        6.720728  5.847183  \n",
      "3        5.465981  4.545588  \n",
      "4        6.964399  4.678121  \n",
      "...           ...       ...  \n",
      "3805     4.089399  5.544073  \n",
      "3806     4.307753  5.872421  \n",
      "3807     4.893987  4.200808  \n",
      "3808     2.878165  5.000853  \n",
      "3809     4.060127  8.562024  \n",
      "\n",
      "[3810 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normalizando o dataset (normalização min-max), para que todos valores estejam no intervalo [1, 10]\n",
    "datasetTreated = ((datasetTreated - datasetTreated.min()) / (datasetTreated.max() - datasetTreated.min())) * 9 + 1\n",
    "\n",
    "print(f'##### Dataset (tratado e normalizado, intervalo [1, 10]) #####\\n{datasetTreated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means CPU\n",
    "# * ####################################\n",
    "\n",
    "# runTests('CPU', 100, TEST_CORRECTEDNESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Time to initialize variables and random centroids: 0.0026415880000000003 s\n",
      "    Time to convert dataset and centroids to Numpy arrays: 0.00052036 s\n",
      "    Time to compute calcLogs(): 0.001514439 s\n",
      "    Time to run 8 iterations of K-Means GPU: 0.031712908000000005 s. Avg per iteration: 0.003964113500000001\n",
      "        Average time per iteration to run calcDistances(): 0.0014337288750000002 s. Total time: 0.011469831000000002 s\n",
      "        Average time per iteration to run calcClosestCentroids(): 0.00149148125 s. Total time: 0.01193185 s\n",
      "        Average time per iteration to calculate new centroids: 0.000999922125 s. Total time: 0.007999377 s\n",
      "Execution K-Means GPU run #1: 0.0365419549998478; curr avg: 0.0365419549998478; \n",
      "    Time to initialize variables and random centroids: 0.0022093990000000003 s\n",
      "    Time to convert dataset and centroids to Numpy arrays: 0.00032033 s\n",
      "    Time to compute calcLogs(): 0.0006565490000000001 s\n",
      "    Time to run 12 iterations of K-Means GPU: 0.027308381000000003 s. Avg per iteration: 0.002275698416666667\n",
      "        Average time per iteration to run calcDistances(): 0.0007156344166666667 s. Total time: 0.008587613000000001 s\n",
      "        Average time per iteration to run calcClosestCentroids(): 0.00042321383333333336 s. Total time: 0.0050785660000000005 s\n",
      "        Average time per iteration to calculate new centroids: 0.0011195218333333334 s. Total time: 0.013434262 s\n",
      "Execution K-Means GPU run #2: 0.030644328995549586; curr avg: 0.033593141997698694; \n",
      "    Time to initialize variables and random centroids: 0.0022473190000000002 s\n",
      "    Time to convert dataset and centroids to Numpy arrays: 0.00038074900000000005 s\n",
      "    Time to compute calcLogs(): 0.0008555300000000001 s\n",
      "    Time to run 11 iterations of K-Means GPU: 0.024938322000000002 s. Avg per iteration: 0.002267120181818182\n",
      "        Average time per iteration to run calcDistances(): 0.0006784749090909091 s. Total time: 0.007463224 s\n",
      "        Average time per iteration to run calcClosestCentroids(): 0.0005434850909090909 s. Total time: 0.005978336000000001 s\n",
      "        Average time per iteration to calculate new centroids: 0.0010316292727272727 s. Total time: 0.011347922 s\n",
      "Execution K-Means GPU run #3: 0.02853843000048073; curr avg: 0.03190823799862604; \n",
      " \n",
      "Avg exec K-Means GPU: 0.03190823799862604\n",
      "Max exec K-Means GPU: 0.0365419549998478\n",
      "Min exec time K-Means GPU: 0.02853843000048073\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means GPU\n",
    "# * ####################################\n",
    "\n",
    "\"\"\" NUMBER_OF_RUNS = 10\n",
    "\n",
    "totalExecTime = 0.0\n",
    "slowestExecTime = -1.0\n",
    "fastestExecTime = FLOAT_MAX\n",
    "\n",
    "totalHits = 0\n",
    "totalHitsTime = 0.0\n",
    "\n",
    "for rep in range(1, NUMBER_OF_RUNS + 1):\n",
    "    startTime = time.time()\n",
    "    results = km.kMeansGPU(datasetTreated, k=K, maxIter=MAX_ITERATIONS, printIter=False, plotResults=PLOT_RESULTS, debug=DEBUG)\n",
    "    elapsedTime = time.time() - startTime\n",
    "    if elapsedTime < fastestExecTime: fastestExecTime = elapsedTime\n",
    "    if elapsedTime > slowestExecTime: slowestExecTime = elapsedTime\n",
    "    totalExecTime += elapsedTime\n",
    "    print(f'Execution K-Means GPU run #{rep}: {elapsedTime}; curr avg: {totalExecTime / rep}; ', end='')\n",
    "\n",
    "    # Verificando acertos\n",
    "    # Converting from numpy arrays to panda's dataframes, if needed\n",
    "    if results.__class__.__name__ != pd.DataFrame.__class__.__name__: results = pd.DataFrame(results)\n",
    "    startTime = time.time()\n",
    "    hits, _, _  = km.getClassificationHits(results, dataset, classColumnName, classes, debug=DEBUG)\n",
    "    elapsedTime = time.time() - startTime\n",
    "    totalHits += hits\n",
    "    totalHitsTime += elapsedTime\n",
    "    print(f'Hits: {hits} (done in {elapsedTime:.4f}); curr avg hits: {totalHits / rep}\\n')\n",
    "\n",
    "print(f' \\nAvg exec K-Means GPU: {totalExecTime / NUMBER_OF_RUNS}')\n",
    "print(f'Max exec K-Means GPU: {slowestExecTime}')\n",
    "print(f'Min exec time K-Means GPU: {fastestExecTime}')\n",
    "\n",
    "print(f' \\nAverage hits: {totalHits / NUMBER_OF_RUNS}')\n",
    "print(f'Avg exec K-Means GPU classificationHits(): {totalHitsTime / NUMBER_OF_RUNS}') \"\"\"\n",
    "\n",
    "runTests('GPU', 3, TEST_CORRECTEDNESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2 (N > 10.000, D = 8, K = 2) — HTRU2\n",
    "\n",
    "Foi utilizado aqui o Dataset **[HTRU2 (High Time Resolution Universe 2)](https://archive.ics.uci.edu/dataset/372/htru2)**, que reúne dados a respeito de emissões de sinais de rádio de banda larga obtidos através de leituras feitas com telescópios de rádio. É um dos resultados da busca por pulsares, estrelas de neutrôn que possuem uma rotação rápida e que emitem sinais de rádio banda larga detectáveis do nosso planeta. Temos **8 variáveis (D = 8)** e **17.898 instâncias**.\n",
    "\n",
    "Esse dataset também contém informações de classe, definindo se a leitura é **positiva** ou **negativa**, a respeito do sinal candidato de fato originar ou não de um pulsar. Portanto, haverão **2 grupos de dados (K = 2)**.\n",
    "\n",
    "Esse conjunto de dados está presente no arquivo `HTRU_2.csv` dentro do arquivo `HTRU_2.zip` do dataset (também disponível em download direto [neste link](https://archive.ics.uci.edu/static/public/372/htru2.zip)).\n",
    "\n",
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          mean_IP  std_dev_IP  exc_kurt_IP   skew_IP  mean_DM_SNR   \n",
      "0      140.562500   55.683782    -0.234571 -0.699648     3.199833  \\\n",
      "1      102.507812   58.882430     0.465318 -0.515088     1.677258   \n",
      "2      103.015625   39.341649     0.323328  1.051164     3.121237   \n",
      "3      136.750000   57.178449    -0.068415 -0.636238     3.642977   \n",
      "4       88.726562   40.672225     0.600866  1.123492     1.178930   \n",
      "...           ...         ...          ...       ...          ...   \n",
      "17893  136.429688   59.847421    -0.187846 -0.738123     1.296823   \n",
      "17894  122.554688   49.485605     0.127978  0.323061    16.409699   \n",
      "17895  119.335938   59.935939     0.159363 -0.743025    21.430602   \n",
      "17896  114.507812   53.902400     0.201161 -0.024789     1.946488   \n",
      "17897   57.062500   85.797340     1.406391  0.089520   188.306020   \n",
      "\n",
      "       std_dev_DM_SNR  exc_kurt_DM_SNR  skew_DM_SNR  \n",
      "0           19.110426         7.975532    74.242225  \n",
      "1           14.860146        10.576487   127.393580  \n",
      "2           21.744669         7.735822    63.171909  \n",
      "3           20.959280         6.896499    53.593661  \n",
      "4           11.468720        14.269573   252.567306  \n",
      "...               ...              ...          ...  \n",
      "17893       12.166062        15.450260   285.931022  \n",
      "17894       44.626893         2.945244     8.297092  \n",
      "17895       58.872000         2.499517     4.595173  \n",
      "17896       13.381731        10.007967   134.238910  \n",
      "17897       64.712562        -1.597527     1.429475  \n",
      "\n",
      "[17898 rows x 8 columns]\n",
      "Classes (from column \"is_positive\"): [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Novas variáveis globais\n",
    "K = 2\n",
    "MAX_ITERATIONS = 60\n",
    "PLOT_RESULTS = False\n",
    "DEBUG = False\n",
    "\n",
    "datasetFilePath = './htru2/HTRU_2.csv'\n",
    "\n",
    "columnNames = ['mean_IP', 'std_dev_IP', 'exc_kurt_IP', 'skew_IP', 'mean_DM_SNR', 'std_dev_DM_SNR', 'exc_kurt_DM_SNR', 'skew_DM_SNR', 'is_positive']\n",
    "\n",
    "# Lendo dataset do arquivo\n",
    "with open(datasetFilePath, 'r') as datasetFile:\n",
    "    dataset = pd.read_csv(datasetFilePath, names=columnNames, sep=',')\n",
    "\n",
    "datasetTreated = dataset.drop(columns=['is_positive'])\n",
    "print(datasetTreated)\n",
    "\n",
    "classColumnName = 'is_positive'\n",
    "classes = dataset[classColumnName].unique()\n",
    "\n",
    "print(f'Classes (from column \"{classColumnName}\"): {classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Dataset (tratado e normalizado, intervalo [1, 10]) #####\n",
      "        mean_IP  std_dev_IP  exc_kurt_IP   skew_IP  mean_DM_SNR   \n",
      "0      7.492075    4.759187     2.485386  1.140645     1.120440  \\\n",
      "1      5.658651    5.148176     3.118736  1.164410     1.059040   \n",
      "2      5.683117    2.771815     2.990246  1.366092     1.117270   \n",
      "3      7.308394    4.940954     2.635746  1.148810     1.138310   \n",
      "4      4.994689    2.933627     3.241398  1.375405     1.038944   \n",
      "...         ...         ...          ...       ...          ...   \n",
      "17893  7.292961    5.265529     2.527670  1.135690     1.043698   \n",
      "17894  6.624482    4.005425     2.813468  1.272336     1.653146   \n",
      "17895  6.469407    5.276293     2.841869  1.135059     1.855621   \n",
      "17896  6.236795    4.542553     2.879693  1.227544     1.069897   \n",
      "17897  3.469156    8.421307     3.970340  1.242264     8.585104   \n",
      "\n",
      "       std_dev_DM_SNR  exc_kurt_DM_SNR  skew_DM_SNR  \n",
      "0            2.023125         3.654872     1.575009  \n",
      "1            1.652719         4.276134     1.975990  \n",
      "2            2.252696         3.597615     1.491493  \n",
      "3            2.184250         3.397135     1.419233  \n",
      "4            1.357160         5.158261     2.920319  \n",
      "...               ...              ...          ...  \n",
      "17893        1.417933         5.440279     3.172020  \n",
      "17894        4.246852         2.453342     1.077509  \n",
      "17895        5.488294         2.346876     1.049581  \n",
      "17896        1.523877         4.140337     2.027633  \n",
      "17897        5.997291         1.368259     1.025699  \n",
      "\n",
      "[17898 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normalizando o dataset (normalização min-max), para que todos valores estejam no intervalo [1, 10]\n",
    "datasetTreated = ((datasetTreated - datasetTreated.min()) / (datasetTreated.max() - datasetTreated.min())) * 9 + 1\n",
    "\n",
    "print(f'##### Dataset (tratado e normalizado, intervalo [1, 10]) #####\\n{datasetTreated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means CPU\n",
    "# * ####################################\n",
    "\n",
    "# runTests('CPU', 100, TEST_CORRECTEDNESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means GPU\n",
    "# * ####################################\n",
    "\n",
    "# runTests('GPU', 100, TEST_CORRECTEDNESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3 (N > 100.000, D = 50, K = 2) — MiniBooNE\n",
    "\n",
    "Foi utilizado aqui o Dataset **[MiniBooNE Particle Identification](https://archive.ics.uci.edu/dataset/199/miniboone+particle+identification)**, que reúne dados a respeito de partículas detectadas no experimento *MiniBooNE* (*Mini Booster Neutrino Experiment*), conduzido no laboratório americano *Fermilab*. Cada detecção de partícula é descrita por **50 variáveis reais (D = 50)** e há **129.596 instâncias no total**.\n",
    "\n",
    "As primeiras 36.488 instâncias são detecções de neutrinos do elétron (sinal) e as 93.108 restantes são de neutrinos do múon (ruído de fundo). Assim, as informações de classe desse dataset estão implícitas, expressa pela ordem das instâncias no arquivo. Como temos duas classes, haverão **2 grupos de dados (K = 2)**.\n",
    "\n",
    "Esse conjunto de dados está presente no arquivo `MiniBooNE_PID.txt` dentro do arquivo `miniboone+particle+identification.zip` do dataset (também disponível em download direto [neste link](https://archive.ics.uci.edu/static/public/199/miniboone+particle+identification.zip)).\n",
    "\n",
    "Foi necessário, neste dataset, realizar um **pré-processamento** para **remoção de outliers**. Originalmente, há 130.064 instâncias no total (36.499 sinal e 93.565 ruído). Porém, existem 468 instâncias (11 sinal e 457 ruído) que são extremos outliers, possuindo o valor -999.0 em todas as 50 variáveis — provavelmente advindos de algum erro de detecção. A presença destes outliers causava a criação de um cluster contendo apenas estes outliers, diminuindo muito o tempo de execução do algoritmo de maneira artificial. Estes outliers tiveram que ser removidos. Note que poderíamos ter solucionado este problema com outra abordagem: aumentar K para 3, criando um cluster novo para conter apenas os outliers. Isso, no entanto, seria mais custoso computacionalmente do que a remoção das instâncias.\n",
    "\n",
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset found in ./MiniBooNE_PID.csv. No need for processing!\n",
      " \n",
      "        id_var_1  id_var_2  id_var_3  id_var_4  id_var_5  id_var_6  id_var_7   \n",
      "0        2.59413  0.468803   20.6916  0.322648  0.009682  0.374393  0.803479  \\\n",
      "1        3.86388  0.645781   18.1375  0.233529  0.030733  0.361239  1.069740   \n",
      "2        3.38584  1.197140   36.0807  0.200866  0.017341  0.260841  1.108950   \n",
      "3        4.28524  0.510155  674.2010  0.281923  0.009174  0.000000  0.998822   \n",
      "4        5.93662  0.832993   59.8796  0.232853  0.025066  0.233556  1.370040   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "129591   4.80718  1.451020  174.6920  0.343481  0.002174  0.000000  0.747401   \n",
      "129592   5.00527  1.501860  129.9270  0.273477  0.006098  0.109769  1.325370   \n",
      "129593   3.10842  2.178140   56.3651  0.211850  0.000000  0.167382  1.318900   \n",
      "129594   5.44560  1.845700  103.4630  0.287411  0.015929  0.107495  0.679931   \n",
      "129595   4.55062  1.341740   80.0887  0.283594  0.000000  0.176268  0.623019   \n",
      "\n",
      "        id_var_8  id_var_9  id_var_10  ...  id_var_41  id_var_42  id_var_43   \n",
      "0       0.896592   3.59665   0.249282  ...    101.174  -31.37300   0.442259  \\\n",
      "1       0.878714   3.59243   0.200793  ...    186.516   45.95970  -0.478507   \n",
      "2       0.884405   3.43159   0.177167  ...    129.931  -11.56080  -0.297008   \n",
      "3       0.823390   3.16382   0.171678  ...    163.978  -18.45860   0.453886   \n",
      "4       0.787424   3.66546   0.174862  ...    229.555   42.96000  -0.975752   \n",
      "...          ...       ...        ...  ...        ...        ...        ...   \n",
      "129591  0.725617   3.18501   0.152208  ...    179.832   -2.74376   0.317051   \n",
      "129592  0.830334   3.40836   0.130794  ...    120.794  -24.72180   0.312652   \n",
      "129593  0.870681   3.43055   0.279588  ...     83.082  -34.31190   0.360148   \n",
      "129594  0.786533   3.47714   0.193390  ...    170.225   16.61940   0.164154   \n",
      "129595  0.843997   3.21611   0.160869  ...    168.217    4.84619  -0.302852   \n",
      "\n",
      "        id_var_44  id_var_45  id_var_46  id_var_47  id_var_48  id_var_49   \n",
      "0         5.86453   0.000000   0.090519   0.176909   0.457585   0.071769  \\\n",
      "1         6.11126   0.001182   0.091800  -0.465572   0.935523   0.333613   \n",
      "2         8.27204   0.003854   0.141721  -0.210559   1.013450   0.255512   \n",
      "3         2.48112   0.000000   0.180938   0.407968   4.341270   0.473081   \n",
      "4         2.66109   0.000000   0.170836  -0.814403   4.679490   1.924990   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "129591    2.67617   0.000000   0.141958   0.723207   7.446300   3.219320   \n",
      "129592    4.16524   0.000000   0.232273   0.141153   1.898750   1.778180   \n",
      "129593    8.16491   0.000000   0.124182   0.016155   0.789276   0.730342   \n",
      "129594    5.83085   0.000000   0.193383  -0.397099   2.872590   0.819867   \n",
      "129595    2.82402   0.000000   0.107446   0.321685   2.647440   0.742709   \n",
      "\n",
      "        id_var_50  \n",
      "0        0.245996  \n",
      "1        0.230621  \n",
      "2        0.180901  \n",
      "3        0.258990  \n",
      "4        0.253893  \n",
      "...           ...  \n",
      "129591   0.299487  \n",
      "129592   0.258058  \n",
      "129593   0.152876  \n",
      "129594   0.210619  \n",
      "129595   0.276477  \n",
      "\n",
      "[129596 rows x 50 columns]\n",
      "Classes (from column \"class\"): ['signal', 'noise']\n"
     ]
    }
   ],
   "source": [
    "# Novas variáveis globais\n",
    "K = 2\n",
    "MAX_ITERATIONS = 60\n",
    "PLOT_RESULTS = False\n",
    "DEBUG = False\n",
    "\n",
    "COMMENT_CHAR = '#'\n",
    "\n",
    "# As primeiras 36.499 instâncias são consideradas um sinal, e o resto como ruído\n",
    "N_OF_SIGNAL_LINES = 36499\n",
    "\n",
    "datasetFilePath = './MiniBooNE_PID.csv'\n",
    "\n",
    "# Processando o aqruivo .txt file e convertendo para um arquivo .csv válido (com a primeira linha comentada, removendo o leading whitespace, e trocando o separador de \"  \" ou \" \" para \",\")\n",
    "if not os.path.exists(datasetFilePath):\n",
    "    with \\\n",
    "        open('./MiniBooNE_PID.txt', 'r') as file,\\\n",
    "        open(datasetFilePath, 'w') as fileNew:\n",
    "\n",
    "        print('Processing MiniBooNE_PID.txt...\\n ')\n",
    "\n",
    "        # Removendo outliers com -999.0 de valor nas 50 variáveis. Há 468 destas instâncias\n",
    "        outlierString = '''-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03,-0.999000E+03'''\n",
    "\n",
    "        index = 1\n",
    "        signalInstRemoved = 0\n",
    "        noiseInstRemoved = 0\n",
    "        for line in file:\n",
    "            if index != 1:\n",
    "                lineToWrite = line.strip(' ').replace('  ', ' ').replace(' ', ',')\n",
    "                if outlierString not in lineToWrite:\n",
    "                    fileNew.write(lineToWrite)\n",
    "                else:\n",
    "                    if index - 1 <= N_OF_SIGNAL_LINES:\n",
    "                        # print(f'Instance (signal) #{index - 1} removed...')\n",
    "                        signalInstRemoved += 1\n",
    "                    else:\n",
    "                        # print(f'Instance (noise) #{index - 1} removed...')\n",
    "                        noiseInstRemoved += 1\n",
    "            # else:\n",
    "            #     fileNew.write(COMMENT_CHAR + ' ' + line.strip(' ').replace('  ', ' '))\n",
    "            index += 1\n",
    "\n",
    "        print(f'Signal outlier instances removed = {signalInstRemoved}')\n",
    "        print(f'Noise outlier instances removed = {noiseInstRemoved}\\n ')\n",
    "\n",
    "        print(f'Processed dataset saved in {datasetFilePath} with success!\\n ')\n",
    "else:\n",
    "    print(f'Processed dataset found in {datasetFilePath}. No need for processing!\\n ')\n",
    "\n",
    "columnNames = [f'id_var_{i}' for i in range(1, 50 + 1) ]\n",
    "\n",
    "# Lendo dataset do arquivo\n",
    "with open(datasetFilePath, 'r') as datasetFile:\n",
    "    dataset = pd.read_csv(datasetFile, names=columnNames, sep=',', skip_blank_lines=True)\n",
    "\n",
    "# Gerando coluna de classes\n",
    "classColumn = pd.DataFrame(['signal' if idx <= 36488 else 'noise' for idx in range(1, len(dataset) + 1)])\n",
    "# print(classColumn)\n",
    "\n",
    "classColumnName = 'class'\n",
    "dataset.insert(len(dataset.columns), classColumnName, classColumn)\n",
    "del classColumn\n",
    "\n",
    "datasetTreated = dataset.drop(columns=[classColumnName])\n",
    "print(datasetTreated)\n",
    "\n",
    "classes = ['signal', 'noise']\n",
    "print(f'Classes (from column \"{classColumnName}\"): {classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Dataset (tratado e normalizado, intervalo [1, 10]) #####\n",
      "        id_var_1  id_var_2  id_var_3  id_var_4  id_var_5  id_var_6  id_var_7   \n",
      "0       2.368749  1.421131  1.039201  4.103207  5.452597  5.787233  2.158663  \\\n",
      "1       3.038712  1.603309  1.034359  2.834322  6.017928  5.619037  2.542627   \n",
      "2       2.786482  2.170867  1.068374  2.369263  5.658285  4.335283  2.599170   \n",
      "3       3.261035  1.463698  2.278040  3.523361  5.438966  1.000000  2.440359   \n",
      "4       4.132359  1.796021  1.113489  2.824697  5.865742  3.986399  2.975677   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "129591  3.536428  2.432206  1.331135  4.399829  5.250969  1.000000  2.077796   \n",
      "129592  3.640947  2.484539  1.246275  3.403106  5.356339  2.403578  2.911261   \n",
      "129593  2.640106  3.180688  1.106826  2.525655  5.192588  3.140255  2.901930   \n",
      "129594  3.873280  2.838481  1.196108  3.601499  5.620371  2.374501  1.980500   \n",
      "129595  3.401059  2.319715  1.151798  3.547153  5.192588  3.253878  1.898430   \n",
      "\n",
      "        id_var_8  id_var_9  id_var_10  ...  id_var_41  id_var_42  id_var_43   \n",
      "0       9.123524  3.292523   4.952846  ...   3.031707   6.840970   1.422581  \\\n",
      "1       8.955252  3.284602   4.064871  ...   5.608892   8.108915   1.239799   \n",
      "2       9.008817  2.982707   3.632209  ...   3.900120   7.165810   1.275828   \n",
      "3       8.434529  2.480104   3.531690  ...   4.928282   7.052714   1.424889   \n",
      "4       8.096009  3.421679   3.589998  ...   6.908598   8.059732   1.141091   \n",
      "...          ...       ...        ...  ...        ...        ...        ...   \n",
      "129591  7.514267  2.519877   3.175137  ...   5.407047   7.310374   1.397725   \n",
      "129592  8.499888  2.939104   2.782984  ...   3.624198   6.950023   1.396852   \n",
      "129593  8.879643  2.980755   5.507838  ...   2.485359   6.792784   1.406281   \n",
      "129594  8.087623  3.068204   3.929300  ...   5.116931   7.627852   1.367374   \n",
      "129595  8.628487  2.578252   3.333745  ...   5.056293   7.434819   1.274668   \n",
      "\n",
      "        id_var_44  id_var_45  id_var_46  id_var_47  id_var_48  id_var_49   \n",
      "0        1.590578   1.000000   2.345075   9.535764   4.560597   4.491605  \\\n",
      "1        1.616527   1.023804   2.364123   9.365909   4.682587   4.548499   \n",
      "2        1.843782   1.077603   3.105925   9.433328   4.702478   4.531529   \n",
      "3        1.234737   1.000000   3.688675   9.596850   5.551883   4.578802   \n",
      "4        1.253665   1.000000   3.538563   9.273687   5.638212   4.894274   \n",
      "...           ...        ...        ...        ...        ...        ...   \n",
      "129591   1.255251   1.000000   3.109446   9.680191   6.344423   5.175507   \n",
      "129592   1.411860   1.000000   4.451496   9.526311   4.928445   4.862375   \n",
      "129593   1.832514   1.000000   2.845301   9.493265   4.645259   4.634700   \n",
      "129594   1.587036   1.000000   3.873604   9.384012   5.177012   4.654152   \n",
      "129595   1.270801   1.000000   2.596610   9.574039   5.119544   4.637387   \n",
      "\n",
      "        id_var_50  \n",
      "0        4.539601  \n",
      "1        4.318373  \n",
      "2        3.602959  \n",
      "3        4.726570  \n",
      "4        4.653230  \n",
      "...           ...  \n",
      "129591   5.309276  \n",
      "129592   4.713160  \n",
      "129593   3.199711  \n",
      "129594   4.030567  \n",
      "129595   4.978188  \n",
      "\n",
      "[129596 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normalizando o dataset (normalização min-max), para que todos valores estejam no intervalo [1, 10]\n",
    "datasetTreated = ((datasetTreated - datasetTreated.min()) / (datasetTreated.max() - datasetTreated.min())) * 9 + 1\n",
    "\n",
    "print(f'##### Dataset (tratado e normalizado, intervalo [1, 10]) #####\\n{datasetTreated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means CPU\n",
    "# * ####################################\n",
    "\n",
    "# runTests('CPU', 100, TEST_CORRECTEDNESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Time to get random centroids: 0.111394297 s\n",
      "    Time to convert dataset and centroids to Numpy arrays: 0.00030076 s\n",
      "    Time to compute calcLogs(): 0.021381874000000002 s\n",
      "    Time to run 36 iterations of K-Means GPU: 1.9067306890000002 s. Avg per iteration: 0.052964741361111116\n",
      "        Average time per iteration to run calcDistances(): 0.007438895861111111 s. Total time: 0.267800251 s\n",
      "        Average time per iteration to run calcClosestCentroids(): 0.0022579695833333338 s. Total time: 0.081286905 s\n",
      "        Average time per iteration to calculate new centroids: 0.04322678591666667 s. Total time: 1.5561642930000001 s\n",
      "Execution K-Means GPU run #1: 2.0407283999957144; curr avg: 2.0407283999957144; \n",
      "    Time to get random centroids: 0.103317458 s\n",
      "    Time to convert dataset and centroids to Numpy arrays: 0.00023198 s\n",
      "    Time to compute calcLogs(): 0.019962706 s\n",
      "    Time to run 40 iterations of K-Means GPU: 2.0874071670000003 s. Avg per iteration: 0.052185179175000006\n",
      "        Average time per iteration to run calcDistances(): 0.007534487550000001 s. Total time: 0.301379502 s\n",
      "        Average time per iteration to run calcClosestCentroids(): 0.001688372425 s. Total time: 0.06753489700000001 s\n",
      "        Average time per iteration to calculate new centroids: 0.04292757625 s. Total time: 1.7171030500000002 s\n",
      "Execution K-Means GPU run #2: 2.2117550789989764; curr avg: 2.1262417394973454; \n",
      "    Time to get random centroids: 0.10092461000000001 s\n",
      "    Time to convert dataset and centroids to Numpy arrays: 0.00019919000000000002 s\n",
      "    Time to compute calcLogs(): 0.013947413 s\n",
      "    Time to run 34 iterations of K-Means GPU: 1.7836583810000002 s. Avg per iteration: 0.052460540617647065\n",
      "        Average time per iteration to run calcDistances(): 0.007525937588235295 s. Total time: 0.255881878 s\n",
      "        Average time per iteration to run calcClosestCentroids(): 0.0017275979411764707 s. Total time: 0.058738330000000005 s\n",
      "        Average time per iteration to calculate new centroids: 0.0431728845 s. Total time: 1.467878073 s\n",
      "Execution K-Means GPU run #3: 1.8994552519943682; curr avg: 2.0506462436630195; \n",
      "    Time to get random centroids: 0.101992989 s\n",
      "    Time to convert dataset and centroids to Numpy arrays: 0.000205679 s\n",
      "    Time to compute calcLogs(): 0.018477299000000003 s\n",
      "    Time to run 45 iterations of K-Means GPU: 2.419627937 s. Avg per iteration: 0.053769509711111114\n",
      "        Average time per iteration to run calcDistances(): 0.007625497822222223 s. Total time: 0.34314740200000005 s\n",
      "        Average time per iteration to run calcClosestCentroids(): 0.001930680666666667 s. Total time: 0.08688063 s\n",
      "        Average time per iteration to calculate new centroids: 0.04417288595555556 s. Total time: 1.987779868 s\n",
      "Execution K-Means GPU run #4: 2.5411178240028676; curr avg: 2.1732641387479816; \n",
      "    Time to get random centroids: 0.10421015700000001 s\n",
      "    Time to convert dataset and centroids to Numpy arrays: 0.00025311 s\n",
      "    Time to compute calcLogs(): 0.013623934 s\n",
      "    Time to run 41 iterations of K-Means GPU: 2.236906858 s. Avg per iteration: 0.05455870385365854\n",
      "        Average time per iteration to run calcDistances(): 0.007859705731707318 s. Total time: 0.32224793500000004 s\n",
      "        Average time per iteration to run calcClosestCentroids(): 0.001938326512195122 s. Total time: 0.079471387 s\n",
      "        Average time per iteration to calculate new centroids: 0.04471945385365854 s. Total time: 1.833497608 s\n",
      "Execution K-Means GPU run #5: 2.3558725559996674; curr avg: 2.209785822198319; \n",
      " \n",
      "Avg exec K-Means GPU: 2.209785822198319\n",
      "Max exec K-Means GPU: 2.5411178240028676\n",
      "Min exec time K-Means GPU: 1.8994552519943682\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means GPU\n",
    "# * ####################################\n",
    "\n",
    "runTests('GPU', 5, TEST_CORRECTEDNESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 4 (N > 1.000.000, D = 8) — WESAD\n",
    "\n",
    "Foi utilizado aqui um sub-conjunto dos dados do Dataset **[WESAD (Wearable Stress and Affect Detection)](https://archive.ics.uci.edu/dataset/465/wesad+wearable+stress+and+affect+detection)**, que reúne dados, fisiológicos e de movimento, de diversos sensores presentes em aparelhos *wearables* usados por 15 pacientes diferentes em testes laboratoriais. Um aparelho foi usado no peitoral e outro no pulso dos pacientes.\n",
    "\n",
    "Esse dataset também contém informações de classe, definindo momentos dos testes como pertencendo à três classificações de emoção do paciente: **referência**, **estresse** ou **diversão**. Portanto, haverão **3 grupos de dados (K = 3)**.\n",
    "\n",
    "O sub-conjunto de dados utilizado foi: dados obtidos apenas através do **aparelho usado no peito** do paciente, e apenas do **paciente #4**. Utilizando este sub-conjunto, temos **8 variáveis (D = 8)** e **4.588.552 instâncias**, cada uma sendo uma leitura ao longo do tempo do teste laboratorial (leituras realizadas na frequência de 700hz).\n",
    "\n",
    "Esse sub-conjunto de dados está presente no arquivo `S4/S4_respiban.txt` dentro do arquivo `WESAD.zip` do dataset (também disponível em download direto [neste link](https://uni-siegen.sciebo.de/s/HGdUkoNlW1Ub0Gx/download)).\n",
    "\n",
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0\n",
      "0        base\n",
      "1        base\n",
      "2        base\n",
      "3        base\n",
      "4        base\n",
      "...       ...\n",
      "4588548  base\n",
      "4588549  base\n",
      "4588550  base\n",
      "4588551  base\n",
      "4588552  base\n",
      "\n",
      "[4588553 rows x 1 columns]\n",
      "           ECG   EDA    EMG   TEMP  spatialX  spatialY  spatialZ  RESPIRATION\n",
      "index                                                                        \n",
      "0        34487  2844  32819  27563     37495     32437     31921        33292\n",
      "1        34274  2869  32481  27560     37485     32433     31935        33295\n",
      "2        33960  2774  32431  27557     37471     32445     31927        33293\n",
      "3        33737  2767  32561  27555     37485     32433     31925        33308\n",
      "4        33602  2768  32696  27562     37487     32429     31909        33300\n",
      "...        ...   ...    ...    ...       ...       ...       ...          ...\n",
      "4588548  33272  6470  32721  26727     37539     32597     32256        31863\n",
      "4588549  33389  6467  32360  26726     37543     32583     32253        31865\n",
      "4588550  33497  6456  32357  26719     37530     32598     32243        31857\n",
      "4588551  33499  6450  32175  26733     37539     32585     32263        31855\n",
      "4588552  33425  6445  32340  26753     37525     32595     32237        31847\n",
      "\n",
      "[4588553 rows x 8 columns]\n",
      "Classes (from column \"class\"): ['base', 'fun', 'stress']\n"
     ]
    }
   ],
   "source": [
    "# Novas variáveis globais\n",
    "K = 3\n",
    "MAX_ITERATIONS = 60\n",
    "PLOT_RESULTS = False\n",
    "DEBUG = False\n",
    "\n",
    "datasetFilePath = './WESAD/S4/S4_respiban.txt'\n",
    "columnNames = ['index', 'DI', 'ECG', 'EDA', 'EMG', 'TEMP', 'spatialX', 'spatialY', 'spatialZ', 'RESPIRATION', '_ignore_']\n",
    "\n",
    "# Lendo dataset do arquivo\n",
    "with open(datasetFilePath, 'r') as datasetFile:\n",
    "    dataset = pd.read_csv(datasetFilePath, names=columnNames, sep='\\t', index_col=0, skip_blank_lines=True, comment='#')\n",
    "\n",
    "# datasetTreated = dataset.drop(columns=['DI', '_ignore_'])\n",
    "# print(datasetTreated)\n",
    "\n",
    "# classColumnName = 'DI'\n",
    "# classes = dataset[classColumnName].unique()\n",
    "\n",
    "# print(f'Classes (from column \"{classColumnName}\"): {classes}')\n",
    "\n",
    "# Gerando coluna de classes\n",
    "classColumn = []\n",
    "for idx in range(len(dataset)):\n",
    "    classification = None\n",
    "    if idx < 1329300: classification = 'base'\n",
    "    elif idx < 1926400: classification = 'fun'\n",
    "    elif idx < 2563400: classification = 'base' # Medi 1\n",
    "    elif idx < 4020100: classification = 'stress'\n",
    "    else: classification = 'base' # Medi 2\n",
    "\n",
    "    classColumn.append(classification)\n",
    "classColumn = pd.DataFrame(classColumn)\n",
    "print(classColumn)\n",
    "\n",
    "classColumnName = 'class'\n",
    "dataset.insert(len(dataset.columns), classColumnName, classColumn)\n",
    "del classColumn\n",
    "\n",
    "datasetTreated = dataset.drop(columns=['DI', '_ignore_', classColumnName])\n",
    "print(datasetTreated)\n",
    "\n",
    "classes = ['base', 'fun', 'stress']\n",
    "print(f'Classes (from column \"{classColumnName}\"): {classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Dataset (tratado e normalizado, intervalo [1, 10]) #####\n",
      "              ECG       EDA       EMG      TEMP  spatialX  spatialY  spatialZ   \n",
      "index                                                                           \n",
      "0        5.735295  1.508909  4.175522  8.925593  5.800000  5.203079  4.600799  \\\n",
      "1        5.706038  1.527215  3.927640  8.903516  5.789437  5.196481  4.607789   \n",
      "2        5.662907  1.457652  3.890971  8.881439  5.774648  5.216276  4.603795   \n",
      "3        5.632276  1.452526  3.986310  8.866721  5.789437  5.196481  4.602796   \n",
      "4        5.613733  1.453258  4.085316  8.918234  5.791549  5.189883  4.594808   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "4588548  5.568405  4.164022  4.103651  2.773508  5.846479  5.467009  4.768057   \n",
      "4588549  5.584475  4.161826  3.838902  2.766149  5.850704  5.443915  4.766559   \n",
      "4588550  5.599310  4.153771  3.836701  2.714636  5.836972  5.468658  4.761567   \n",
      "4588551  5.599585  4.149378  3.703227  2.817661  5.846479  5.447214  4.771552   \n",
      "4588552  5.589420  4.145716  3.824234  2.964841  5.831690  5.463710  4.758571   \n",
      "\n",
      "         RESPIRATION  \n",
      "index                 \n",
      "0           5.634836  \n",
      "1           5.635812  \n",
      "2           5.635161  \n",
      "3           5.640040  \n",
      "4           5.637438  \n",
      "...              ...  \n",
      "4588548     5.169986  \n",
      "4588549     5.170636  \n",
      "4588550     5.168034  \n",
      "4588551     5.167384  \n",
      "4588552     5.164781  \n",
      "\n",
      "[4588553 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normalizando o dataset (normalização min-max), para que todos valores estejam no intervalo [1, 10]\n",
    "datasetTreated = ((datasetTreated - datasetTreated.min()) / (datasetTreated.max() - datasetTreated.min())) * 9 + 1\n",
    "\n",
    "print(f'##### Dataset (tratado e normalizado, intervalo [1, 10]) #####\\n{datasetTreated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means CPU\n",
    "# * ####################################\n",
    "\n",
    "# runTests('CPU', 20, TEST_CORRECTEDNESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Time to initialize variables and random centroids: 0.00015536 s\n",
      "    Time to convert dataset and centroids to Numpy arrays: 0.000367329 s\n",
      "Initial centroids =           0         1         2\n",
      "0  5.430634  5.478984  5.050563\n",
      "1  1.852331  2.309251  2.061753\n",
      "2  4.172588  4.205590  4.165254\n",
      "3  7.100572  4.730989  8.174980\n",
      "4  4.855634  5.286620  5.793662\n",
      "5  2.283358  2.987720  5.090909\n",
      "6  4.003661  4.060579  4.597803\n",
      "7  5.347598  3.953374  5.221058\n",
      "    Time to compute calcLogs(): 0.103431989 s\n",
      "    Time to run 27 iterations of K-Means GPU: 40.637928725 s. Avg per iteration: 1.5051084712962963\n",
      "        Average time per iteration to run calcDistances(): 0.06093674503703704 s. Total time: 1.645292116 s\n",
      "        Average time per iteration to run calcClosestCentroids(): 0.02497021766666667 s. Total time: 0.674195877 s\n",
      "        Average time per iteration to calculate new centroids: 1.419134625 s. Total time: 38.316634875000005 s\n",
      "Execution K-Means GPU run #1: 40.74427357099921; curr avg: 40.74427357099921; \n",
      "    Time to initialize variables and random centroids: 0.00018593 s\n",
      "    Time to convert dataset and centroids to Numpy arrays: 0.000681229 s\n",
      "Initial centroids =           0         1         2\n",
      "0  9.774732  5.262782  5.304539\n",
      "1  1.510373  1.805467  4.327313\n",
      "2  3.761897  4.125652  4.102184\n",
      "3  8.697465  7.372854  3.354865\n",
      "4  5.827465  4.880986  5.597183\n",
      "5  5.900843  2.374084  6.850990\n",
      "6  4.658715  4.044602  5.842505\n",
      "7  5.999819  5.314743  5.442585\n",
      "    Time to compute calcLogs(): 0.083707894 s\n",
      "    Time to run 17 iterations of K-Means GPU: 24.962449856000003 s. Avg per iteration: 1.4683794032941178\n",
      "        Average time per iteration to run calcDistances(): 0.05939610505882353 s. Total time: 1.009733786 s\n",
      "        Average time per iteration to run calcClosestCentroids(): 0.02518855094117647 s. Total time: 0.42820536600000003 s\n",
      "        Average time per iteration to calculate new centroids: 1.3837277727058823 s. Total time: 23.523372136000003 s\n",
      "Execution K-Means GPU run #2: 25.049856393998198; curr avg: 32.897064982498705; \n",
      "    Time to initialize variables and random centroids: 0.00015479 s\n",
      "    Time to convert dataset and centroids to Numpy arrays: 0.00045321900000000004 s\n",
      "Initial centroids =           0         1         2\n",
      "0  5.096578  5.283798  5.422942\n",
      "1  4.548450  5.085184  2.086649\n",
      "2  4.091917  5.331323  3.912239\n",
      "3  2.295176  2.596893  6.519215\n",
      "4  5.079577  5.461972  5.030986\n",
      "5  2.842559  6.657991  4.859971\n",
      "6  4.059581  5.876956  3.774492\n",
      "7  5.773738  5.569451  5.773087\n",
      "    Time to compute calcLogs(): 0.088125717 s\n",
      "    Time to run 12 iterations of K-Means GPU: 18.123136402 s. Avg per iteration: 1.5102613668333333\n",
      "        Average time per iteration to run calcDistances(): 0.059847512750000005 s. Total time: 0.7181701530000001 s\n",
      "        Average time per iteration to run calcClosestCentroids(): 0.024637503583333335 s. Total time: 0.29565004300000003 s\n",
      "        Average time per iteration to calculate new centroids: 1.4257028931666669 s. Total time: 17.108434718 s\n",
      "Execution K-Means GPU run #3: 18.214208714998676; curr avg: 28.002779559998697; \n",
      " \n",
      "Avg exec K-Means GPU: 28.002779559998697\n",
      "Max exec K-Means GPU: 40.74427357099921\n",
      "Min exec time K-Means GPU: 18.214208714998676\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means GPU\n",
    "# * ####################################\n",
    "\n",
    "runTests('GPU', 3, TEST_CORRECTEDNESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados\n",
    "\n",
    "> Resultados completos disponíveis no arquivo `code/examples-and-tests/speedupTestsRawResults.txt`\n",
    "\n",
    "| |Tempo médio (50 execuções)|Speedup Médio|\n",
    "|-|-|-|\n",
    "|K-Means CPU|~129,81s|-|\n",
    "|K-Means GPU|~27,87s|~4,65x|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 5 (N > 10.000.000, D = 3, K = 7) — HHAR\n",
    "\n",
    "Foi utilizado aqui um sub-conjunto dos dados do Dataset **[Heterogeneity Human Activity Recognition (HHAR)](https://archive.ics.uci.edu/dataset/344/heterogeneity+activity+recognition)**, que reúne dados de movimento do giroscópio e acelerômetro presentes em aparelhos celulares (*smartphones*) e relógios (*smartwatches*) usados por 9 usuários diferentes ao realizar diversas atividades físicas diferentes ou estando em repouso.\n",
    "\n",
    "Esse dataset também contém informações de classe, definindo momentos dos testes como pertencendo a uma de seis atividades realizadas: **ciclismo**, **repouso (sentado)**, **repouso (em pé)**, **andar**, **subir escadas** e **descer escadas**. Além disto, há uma sétima \"atividade\", **nula**, que representa espaços do teste onde não foi realizada nenhuma atividade. Portanto, haverão **7 grupos de dados (K = 7)**.\n",
    "\n",
    "O sub-conjunto de dados utilizado foi: dados obtidos apenas através do **giroscópio do smartphone** do usuário. Utilizando este sub-conjunto, temos **3 variáveis (D = 3)** e **13.932.632 instâncias**, cada uma sendo uma leitura ao longo do tempo do experimento.\n",
    "\n",
    "Esse sub-conjunto de dados está presente no arquivo `Activity recognition exp/Phones_gyroscope.csv` dentro do arquivo `heterogeneity+activity+recognition.zip` do dataset (também disponível em download direto [neste link](https://archive.ics.uci.edu/static/public/344/heterogeneity+activity+recognition.zip)).\n",
    "\n",
    "#### Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              x         y         z\n",
      "index                              \n",
      "0      0.013748 -0.000626 -0.023376\n",
      "1      0.014816 -0.001694 -0.022308\n",
      "2      0.015884 -0.001694 -0.021240\n",
      "3      0.016953 -0.003830 -0.020172\n",
      "4      0.015884 -0.007034 -0.020172\n",
      "...         ...       ...       ...\n",
      "11306 -0.046844  0.337667  0.134677\n",
      "11307 -0.117598  0.221777  0.131749\n",
      "11308 -0.177617  0.056115  0.095152\n",
      "11309 -0.195183 -0.124429  0.063191\n",
      "11310 -0.162002 -0.208846  0.043184\n",
      "\n",
      "[13932632 rows x 3 columns]\n",
      "Classes (from column \"gt\"): ['stand' nan 'sit' 'walk' 'stairsup' 'stairsdown' 'bike']\n"
     ]
    }
   ],
   "source": [
    "# Novas variáveis globais\n",
    "K = 7\n",
    "MAX_ITERATIONS = 60\n",
    "PLOT_RESULTS = False\n",
    "DEBUG = False\n",
    "\n",
    "datasetFilePath = './heterogeneity+activity+recognition/Activity recognition exp/Phones_gyroscope.csv'\n",
    "columnNames = ['index', 'arrival_time', 'creation_Time', 'x', 'y', 'z', 'user', 'model', 'device', 'gt']\n",
    "\n",
    "# Lendo dataset do arquivo\n",
    "with open(datasetFilePath, 'r') as datasetFile:\n",
    "    dataset = pd.read_csv(datasetFile, names=columnNames, header=0, sep=',', index_col=0)\n",
    "\n",
    "datasetTreated = dataset.drop(columns=['arrival_time', 'creation_Time', 'user', 'model', 'device', 'gt'])\n",
    "print(datasetTreated)\n",
    "\n",
    "classColumnName = 'gt'\n",
    "classes = dataset[classColumnName].unique()\n",
    "\n",
    "print(f'Classes (from column \"{classColumnName}\"): {classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Dataset (tratado e normalizado, intervalo [1, 10]) #####\n",
      "              x         y         z\n",
      "index                              \n",
      "0      3.820436  4.219502  5.217352\n",
      "1      3.821163  4.219072  5.218209\n",
      "2      3.821890  4.219072  5.219066\n",
      "3      3.822618  4.218211  5.219923\n",
      "4      3.821890  4.216920  5.219923\n",
      "...         ...       ...       ...\n",
      "11306  3.779176  4.355790  5.344196\n",
      "11307  3.730996  4.309101  5.341846\n",
      "11308  3.690126  4.242361  5.312475\n",
      "11309  3.678164  4.169625  5.286825\n",
      "11310  3.700759  4.135616  5.270769\n",
      "\n",
      "[13932632 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normalizando o dataset (normalização min-max), para que todos valores estejam no intervalo [1, 10]\n",
    "datasetTreated = ((datasetTreated - datasetTreated.min()) / (datasetTreated.max() - datasetTreated.min())) * 9 + 1\n",
    "\n",
    "print(f'##### Dataset (tratado e normalizado, intervalo [1, 10]) #####\\n{datasetTreated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution K-Means CPU run #1: 1540.0996360778809; curr avg: 1540.0996360778809; Hits: 3944397 (done in 17880.9985); curr avg hits: 3944397.0\n",
      " \n",
      "Avg exec K-Means CPU: 1540.0996360778809\n",
      "Max exec K-Means CPU: 1540.0996360778809\n",
      "Min exec time K-Means CPU: 1540.0996360778809\n",
      " \n",
      "Average hits: 3944397.0\n",
      "Avg exec K-Means CPU classificationHits(): 17880.998516082764\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means CPU\n",
    "# * ####################################\n",
    "\n",
    "runTests('CPU', 1, TEST_CORRECTEDNESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution K-Means GPU run #1: 568.3950791358948; curr avg: 568.3950791358948; Hits: 3944384 (done in 18560.7951); curr avg hits: 3944384.0\n",
      " \n",
      "Avg exec K-Means GPU: 568.3950791358948\n",
      "Max exec K-Means GPU: 568.3950791358948\n",
      "Min exec time K-Means GPU: 568.3950791358948\n",
      " \n",
      "Average hits: 3944384.0\n",
      "Avg exec K-Means GPU classificationHits(): 18560.795105457306\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# * ####################################\n",
    "# * Rodando o K-Means GPU\n",
    "# * ####################################\n",
    "\n",
    "runTests('GPU', 1, TEST_CORRECTEDNESS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
