Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{FuzzyClusteringSurvey,
abstract = {This paper is a survey of fuzzy set theory applied in cluster analysis. These fuzzy clustering algorithms have been widely studied and applied in a variety of substantive areas. They also become the major techniques in cluster analysis. In this paper, we give a survey of fuzzy clustering in three categories. The first category is the fuzzy clustering based on fuzzy relation. The second one is the fuzzy clustering based on objective function. Finally, we give an overview of a nonparametric classifier. That is the fuzzy generalized k-nearest neighbor rule. {\textcopyright} 1993.},
author = {Yang, M. S.},
doi = {10.1016/0895-7177(93)90202-A},
file = {:C$\backslash$:/Users/Vini/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang - 1993 - A survey of fuzzy clustering.pdf:pdf},
issn = {08957177},
journal = {Mathematical and Computer Modelling},
keywords = {Cluster analysis,Cluster validity,Clustering,Fuzzy Clustering,Fuzzy c-means,Fuzzy c-partitions,Fuzzy clustering,Fuzzy generalized k-nearest neighbor rule,Fuzzy relation},
mendeley-tags = {Clustering,Fuzzy Clustering},
month = {dec},
number = {11},
pages = {1--16},
publisher = {Pergamon},
title = {{A survey of fuzzy clustering}},
url = {https://www.sciencedirect.com/science/article/pii/089571779390202A},
volume = {18},
year = {1993}
}
@article{G-DBSCAN,
abstract = {With the advent of Web 2.0, we see a new and differentiated scenario: There is more data than that can be effectively analyzed. Organizing this data has become one of the biggest problems in Computer Science. Many algorithms have been proposed for this purpose, highlighting those related to the Data Mining area, specifically the clustering algorithms. However, these algorithms are still a computational challenge because of the volume of data that needs to be processed. We found in the literature some proposals to make these algorithms feasible, and, recently, those related to parallelization on graphics processing units (GPUs) have presented good results. In this work we present the G-DBSCAN, a GPU parallel version of one of the most widely used clustering algorithms, the DBSCAN. Although there are other parallel versions of this algorithm, our technique distinguishes itself by the simplicity with which the data are indexed, using graphs, allowing various parallelization opportunities to be explored. In our evaluation we show that the G-DBSCAN using GPU, can be over 100x faster than its sequential version using CPU. {\textcopyright} 2013 The Authors. Published by Elsevier B.V.},
author = {Andrade, Guilherme and Ramos, Gabriel and Madeira, Daniel and Sachetto, Rafael and Ferreira, Renato and Rocha, Leonardo},
doi = {10.1016/j.procs.2013.05.200},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Clustering,Dbscan,GPU,Parallel computing},
pages = {369--378},
title = {{G-DBSCAN: A GPU accelerated algorithm for density-based clustering}},
url = {https://core.ac.uk/download/pdf/82372021.pdf},
volume = {18},
year = {2013}
}
@article{GPU-accelerated-K-Means,
abstract = {Clustering approaches are widely used methodologies to analyse large data sets. The K-means algorithm is well-known as a procedure too computational-intensive for the large data analytic problem. In this work, we focus on a parallel technique to reduce the execution time when the K-means is used to cluster large dataset. We exploit computational powerful of its design when the Graphic Processor Units (GPUs), a massively parallel architecture, is adopted. We optimize the proposed implementation to handle (i) the space limitation issue of GPUs; (ii) the host-device data transfer time. Experimental results, on real and synthetic data, show how our parallelization approach give good results in terms of execution time and speed-up.},
author = {Cuomo, S. and {De Angelis}, V. and Farina, G. and Marcellino, L. and Toraldo, G.},
doi = {10.1016/j.compeleceng.2017.12.002},
issn = {00457906},
journal = {Computers and Electrical Engineering},
keywords = {Clustering,Graphic Processor Units,K-means,Parallel processing},
pages = {262--274},
title = {{A GPU-accelerated parallel K-means algorithm}},
volume = {75},
year = {2019}
}
@article{SoManyClustAlg,
abstract = {We argue that there are many clustering algorithms, because the notion of "cluster" cannot be precisely defined. Clustering is in the eye of the beholder, and as such, researchers have proposed many induction principles and models whose corresponding optimization problem can only be approximately solved by an even larger number of algorithms. Therefore, comparing clustering algorithms, must take into account a careful understanding of the inductive principles involved.},
author = {Estivill-Castro, Vladimir},
doi = {10.1145/568574.568575},
issn = {19310145},
journal = {ACM SIGKDD Explorations Newsletter},
keywords = {Clustering,Clustering Algorithms,General,clustering,clustering criterion,inductive principle},
mendeley-tags = {Clustering,Clustering Algorithms,General},
month = {jun},
number = {1},
pages = {65--75},
publisher = {ACM},
title = {{Why so many clustering algorithms}},
url = {http://portal.acm.org/citation.cfm?doid=568574.568575},
volume = {4},
year = {2002}
}
@misc{CUDAZone,
abstract = {CUDA{\textregistered} is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs). With CUDA, developers are able to dramatically speed up computing applications by harnessing the power of GPUs. In GPU-accelerated applications, the sequential part of the workload runs on the CPU – which is optimized for single-threaded performance – while the compute intensive portion of the application runs on thousands of GPU cores in parallel. When using CUDA, developers program in popular languages such as C, C++, Fortran, Python and MATLAB and express parallelism through extensions in the form of a few basic keywords.},
author = {{NVIDIA Corporation}},
booktitle = {Nvidia},
keywords = {CUDA Documentation,NVIDIA,cuda},
mendeley-tags = {CUDA Documentation,NVIDIA,cuda},
title = {{CUDA Zone}},
url = {https://developer.nvidia.com/cuda-zone},
timestamp = {2019-12-10},
year = {2018}
}
@article{Amdahl-Law,
abstract = {The availability of high-performance, low-cost microprocessors has removed one of the obstacles to construction of multiprocessor systems which are cost-performance competitive from entry levels through large systems. Advances in understanding of computer structure and focus on multiprocessor design practices has removed the performance bottlenecks associated with multiprocessor systems of the past. Better understanding of multiprocessor scheduling and synchronization in the symmetric Pool Processor Architecture built on the portable base of the UNIX system interface has removed the obstacle to easy application of multiprocessors to single applications. Current research work has produced techniques and tools to facilitate and in some cases automate the decomposition of programs to into parallel execution streams. A computer is described which exploits the removal of these barriers. The Balance 8000 is a multimicrocomputer system based on the National Semiconductor Series 32000 microprocessor. It runs DYNIX, a version of UNIX bsd 4. 2, which exploits the power of from 2 to 12 coordinated microprocessors to achieve a range of performance which approaches the sum of the performance of the individual processors.},
address = {New York, NY, USA},
author = {Rodgers, David P.},
doi = {10.1145/327070.327215},
isbn = {0818606347},
issn = {01497111},
journal = {Conference Proceedings - Annual Symposium on Computer Architecture},
number = {3},
pages = {225--231},
publisher = {ACM},
title = {{Improvements in Multiprocessor System Design.}},
url = {http://doi.acm.org/10.1145/327070.327215},
volume = {13},
year = {1985}
}
